{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b10c8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import io\n",
    "import itertools\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, LambdaCallback\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# import datetime\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54de893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Replace 'path/to/your/image.jpg' with the actual path to your image\n",
    "img_path = 'CM_Gender_All.png'\n",
    "\n",
    "# Open the image using Pillow\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# Save the image with a new filename and format (e.g., PNG)\n",
    "output_path = 'CM_Gender_All.png'  # Replace with desired output path and filename\n",
    "img.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8242c985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c0194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset encoding explaination.\n",
    "#image labelling - 0=glasses/sunglasses. 1= trousers/jeans. 3= shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba424d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the datasets and preprocess\n",
    "\n",
    "data_train = np.load(r'Full Dataset/Trousers & Jeans - All - Train.npz')\n",
    "data_validation = np.load(r'Full Dataset/Trousers & Jeans - All - Validation.npz')\n",
    "data_test = np.load(r'Full Dataset/Trousers & Jeans - All - Test.npz')\n",
    "\n",
    "\n",
    "#t extract the arrays from dataset into input(images) and target(labels)\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['genders']\n",
    "\n",
    "images_val = data_validation['images']\n",
    "labels_val = data_validation['genders']\n",
    "\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['genders']\n",
    "\n",
    "#Pixel-wise normalization of the training, validation and testing data\n",
    "images_train = images_train/255.0\n",
    "images_val  = images_val/255.0\n",
    "images_test = images_test/255.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ab0b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameters\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "\n",
    "#Define the hyperparamets to tune and the variations we want to test.\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([3,5,7]))\n",
    "HP_FILTER_NUM = hp.HParam('filter_num', hp.Discrete([32, 64, 96, 128]))\n",
    "\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "#Log the hyperparameter with the file writer\n",
    "with tf.summary.create_file_writer('Logs/ModelG 2/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE, HP_FILTER_NUM], \n",
    "        metrics= [hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de25b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hparams,session_num):\n",
    "    \n",
    "    \n",
    "#Create and train the model\n",
    "\n",
    "\n",
    "    \n",
    "    model = Sequential([\n",
    "                Conv2D(32, 3, activation= 'relu', input_shape=(120,90,3)),\n",
    "                MaxPooling2D(pool_size=(2,2)),\n",
    "                Conv2D(64,3, activation= 'relu'),\n",
    "                MaxPooling2D(pool_size=(2,2)),\n",
    "                Flatten(),\n",
    "                Dense(64, activation = 'relu'),\n",
    "                \n",
    "                Dense(2)\n",
    "    ])\n",
    "\n",
    "\n",
    "#describe the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "#Compile the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "    log_dir = f\"Logs/ModelG 2/fit/run-{session_num}\"\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "#Plot_to_image\n",
    "\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    " \n",
    "        figure = plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Compute the labels from the normalized confusion matrix.\n",
    "        labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "       \n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "\n",
    "\n",
    "        \n",
    "    # log the confusion matrix as a heatmap\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "\n",
    "\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        val_pred_raw = model.predict(images_val)\n",
    "        val_pred = np.argmax(val_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = confusion_matrix(labels_val, val_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=[\"Male\", \"Female\"])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion_matrix\", cm_image, step=epoch)\n",
    "\n",
    "    # Define the per-epoch callback.\n",
    "    cm_callback = LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor= 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "\n",
    "\n",
    "#Train the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val, labels_val),\n",
    "        verbose =2\n",
    "    )\n",
    "\n",
    "    _,accuracy = model.evaluate(images_val, labels_val)\n",
    "\n",
    "    model.save(f\"saved_model/ModelG 2/fit/run-{session_num}\")\n",
    "\n",
    "\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fb505ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-1\n",
      "{'filter_size': 3, 'filter_num': 32}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 65ms/step\n",
      "63/63 - 29s - loss: 0.7393 - accuracy: 0.6598 - val_loss: 0.4941 - val_accuracy: 0.7840 - 29s/epoch - 468ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 61ms/step\n",
      "63/63 - 27s - loss: 0.4095 - accuracy: 0.8207 - val_loss: 0.4155 - val_accuracy: 0.8140 - 27s/epoch - 421ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 61ms/step\n",
      "63/63 - 26s - loss: 0.3477 - accuracy: 0.8564 - val_loss: 0.4025 - val_accuracy: 0.8460 - 26s/epoch - 416ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 62ms/step\n",
      "63/63 - 27s - loss: 0.3298 - accuracy: 0.8564 - val_loss: 0.4130 - val_accuracy: 0.8140 - 27s/epoch - 426ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 64ms/step\n",
      "63/63 - 28s - loss: 0.3210 - accuracy: 0.8669 - val_loss: 0.4594 - val_accuracy: 0.8000 - 28s/epoch - 438ms/step\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.4025 - accuracy: 0.8460\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-2\n",
      "{'filter_size': 3, 'filter_num': 64}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 69ms/step\n",
      "63/63 - 31s - loss: 0.6937 - accuracy: 0.7255 - val_loss: 0.4474 - val_accuracy: 0.8120 - 31s/epoch - 488ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 62ms/step\n",
      "63/63 - 28s - loss: 0.3736 - accuracy: 0.8447 - val_loss: 0.3952 - val_accuracy: 0.8460 - 28s/epoch - 439ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 63ms/step\n",
      "63/63 - 27s - loss: 0.3467 - accuracy: 0.8546 - val_loss: 0.3834 - val_accuracy: 0.8440 - 27s/epoch - 430ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 63ms/step\n",
      "63/63 - 27s - loss: 0.3184 - accuracy: 0.8589 - val_loss: 0.3950 - val_accuracy: 0.8320 - 27s/epoch - 430ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 63ms/step\n",
      "63/63 - 27s - loss: 0.2864 - accuracy: 0.8801 - val_loss: 0.3769 - val_accuracy: 0.8480 - 27s/epoch - 433ms/step\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 1s 62ms/step\n",
      "63/63 - 28s - loss: 0.2548 - accuracy: 0.8966 - val_loss: 0.3512 - val_accuracy: 0.8320 - 28s/epoch - 439ms/step\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 1s 31ms/step\n",
      "63/63 - 20s - loss: 0.2508 - accuracy: 0.9003 - val_loss: 0.3431 - val_accuracy: 0.8540 - 20s/epoch - 323ms/step\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 1s 35ms/step\n",
      "63/63 - 14s - loss: 0.2344 - accuracy: 0.9036 - val_loss: 0.3678 - val_accuracy: 0.8360 - 14s/epoch - 228ms/step\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 1s 33ms/step\n",
      "63/63 - 16s - loss: 0.2126 - accuracy: 0.9158 - val_loss: 0.3459 - val_accuracy: 0.8860 - 16s/epoch - 262ms/step\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.3431 - accuracy: 0.8540\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-3\n",
      "{'filter_size': 3, 'filter_num': 96}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "63/63 - 18s - loss: 0.6348 - accuracy: 0.7068 - val_loss: 0.4950 - val_accuracy: 0.7400 - 18s/epoch - 286ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 37ms/step\n",
      "63/63 - 18s - loss: 0.3954 - accuracy: 0.8272 - val_loss: 0.4174 - val_accuracy: 0.8380 - 18s/epoch - 288ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 17s - loss: 0.3417 - accuracy: 0.8571 - val_loss: 0.3848 - val_accuracy: 0.8460 - 17s/epoch - 271ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "63/63 - 19s - loss: 0.2993 - accuracy: 0.8799 - val_loss: 0.4526 - val_accuracy: 0.7840 - 19s/epoch - 299ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 35ms/step\n",
      "63/63 - 17s - loss: 0.2714 - accuracy: 0.8869 - val_loss: 0.4178 - val_accuracy: 0.8160 - 17s/epoch - 266ms/step\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.3848 - accuracy: 0.8460\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-4\n",
      "{'filter_size': 3, 'filter_num': 128}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 35ms/step\n",
      "63/63 - 19s - loss: 0.5548 - accuracy: 0.7325 - val_loss: 0.4557 - val_accuracy: 0.7780 - 19s/epoch - 299ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 37ms/step\n",
      "63/63 - 16s - loss: 0.3842 - accuracy: 0.8289 - val_loss: 0.4091 - val_accuracy: 0.8240 - 16s/epoch - 251ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 36ms/step\n",
      "63/63 - 16s - loss: 0.3444 - accuracy: 0.8509 - val_loss: 0.4052 - val_accuracy: 0.8220 - 16s/epoch - 256ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 36ms/step\n",
      "63/63 - 15s - loss: 0.2930 - accuracy: 0.8819 - val_loss: 0.3518 - val_accuracy: 0.8680 - 15s/epoch - 246ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 37ms/step\n",
      "63/63 - 16s - loss: 0.2785 - accuracy: 0.8911 - val_loss: 0.3826 - val_accuracy: 0.8440 - 16s/epoch - 258ms/step\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 1s 37ms/step\n",
      "63/63 - 16s - loss: 0.2432 - accuracy: 0.8984 - val_loss: 0.3434 - val_accuracy: 0.8720 - 16s/epoch - 247ms/step\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 1s 34ms/step\n",
      "63/63 - 16s - loss: 0.2185 - accuracy: 0.9143 - val_loss: 0.3473 - val_accuracy: 0.8720 - 16s/epoch - 249ms/step\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 1s 35ms/step\n",
      "63/63 - 15s - loss: 0.2071 - accuracy: 0.9168 - val_loss: 0.3548 - val_accuracy: 0.8760 - 15s/epoch - 246ms/step\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.3434 - accuracy: 0.8720\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-5\n",
      "{'filter_size': 5, 'filter_num': 32}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 48ms/step\n",
      "63/63 - 22s - loss: 0.6980 - accuracy: 0.6883 - val_loss: 0.5089 - val_accuracy: 0.7340 - 22s/epoch - 350ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "63/63 - 20s - loss: 0.4321 - accuracy: 0.8107 - val_loss: 0.4320 - val_accuracy: 0.7920 - 20s/epoch - 316ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "63/63 - 19s - loss: 0.3897 - accuracy: 0.8252 - val_loss: 0.4054 - val_accuracy: 0.7980 - 19s/epoch - 301ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 32ms/step\n",
      "63/63 - 17s - loss: 0.3398 - accuracy: 0.8531 - val_loss: 0.4095 - val_accuracy: 0.8100 - 17s/epoch - 273ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 34ms/step\n",
      "63/63 - 15s - loss: 0.3017 - accuracy: 0.8766 - val_loss: 0.3605 - val_accuracy: 0.8340 - 15s/epoch - 235ms/step\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 1s 34ms/step\n",
      "63/63 - 15s - loss: 0.2655 - accuracy: 0.8929 - val_loss: 0.3869 - val_accuracy: 0.8640 - 15s/epoch - 244ms/step\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 1s 37ms/step\n",
      "63/63 - 16s - loss: 0.2523 - accuracy: 0.8994 - val_loss: 0.3413 - val_accuracy: 0.8800 - 16s/epoch - 249ms/step\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "63/63 - 16s - loss: 0.2322 - accuracy: 0.9138 - val_loss: 0.3583 - val_accuracy: 0.8580 - 16s/epoch - 250ms/step\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 1s 36ms/step\n",
      "63/63 - 18s - loss: 0.2213 - accuracy: 0.9143 - val_loss: 0.4000 - val_accuracy: 0.8480 - 18s/epoch - 284ms/step\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.3413 - accuracy: 0.8800\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-6\n",
      "{'filter_size': 5, 'filter_num': 64}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 42ms/step\n",
      "63/63 - 22s - loss: 0.6302 - accuracy: 0.7068 - val_loss: 0.4752 - val_accuracy: 0.7700 - 22s/epoch - 341ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 45ms/step\n",
      "63/63 - 22s - loss: 0.4168 - accuracy: 0.8124 - val_loss: 0.4305 - val_accuracy: 0.7940 - 22s/epoch - 350ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 47ms/step\n",
      "63/63 - 22s - loss: 0.3522 - accuracy: 0.8516 - val_loss: 0.3765 - val_accuracy: 0.8500 - 22s/epoch - 353ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "63/63 - 22s - loss: 0.3355 - accuracy: 0.8529 - val_loss: 0.3767 - val_accuracy: 0.8200 - 22s/epoch - 356ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 47ms/step\n",
      "63/63 - 21s - loss: 0.2953 - accuracy: 0.8734 - val_loss: 0.3646 - val_accuracy: 0.8260 - 21s/epoch - 332ms/step\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 21s - loss: 0.2858 - accuracy: 0.8836 - val_loss: 0.3542 - val_accuracy: 0.8640 - 21s/epoch - 327ms/step\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "63/63 - 20s - loss: 0.2550 - accuracy: 0.8969 - val_loss: 0.3380 - val_accuracy: 0.8660 - 20s/epoch - 323ms/step\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "63/63 - 19s - loss: 0.2281 - accuracy: 0.9066 - val_loss: 0.3721 - val_accuracy: 0.8560 - 19s/epoch - 308ms/step\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 21s - loss: 0.2434 - accuracy: 0.9021 - val_loss: 0.3512 - val_accuracy: 0.8580 - 21s/epoch - 337ms/step\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.3380 - accuracy: 0.8660\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-7\n",
      "{'filter_size': 5, 'filter_num': 96}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "63/63 - 22s - loss: 0.5931 - accuracy: 0.7105 - val_loss: 0.4681 - val_accuracy: 0.7840 - 22s/epoch - 356ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "63/63 - 20s - loss: 0.3983 - accuracy: 0.8262 - val_loss: 0.3992 - val_accuracy: 0.8300 - 20s/epoch - 322ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 20s - loss: 0.3408 - accuracy: 0.8526 - val_loss: 0.3879 - val_accuracy: 0.8180 - 20s/epoch - 314ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 20s - loss: 0.3167 - accuracy: 0.8749 - val_loss: 0.4160 - val_accuracy: 0.8160 - 20s/epoch - 317ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 22s - loss: 0.2799 - accuracy: 0.8881 - val_loss: 0.3424 - val_accuracy: 0.8780 - 22s/epoch - 344ms/step\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 1s 36ms/step\n",
      "63/63 - 20s - loss: 0.2707 - accuracy: 0.8891 - val_loss: 0.3452 - val_accuracy: 0.8820 - 20s/epoch - 321ms/step\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "63/63 - 18s - loss: 0.2313 - accuracy: 0.9058 - val_loss: 0.3632 - val_accuracy: 0.8660 - 18s/epoch - 289ms/step\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.3424 - accuracy: 0.8780\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-8\n",
      "{'filter_size': 5, 'filter_num': 128}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "63/63 - 21s - loss: 0.7696 - accuracy: 0.6928 - val_loss: 0.5580 - val_accuracy: 0.7080 - 21s/epoch - 332ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 19s - loss: 0.4403 - accuracy: 0.8037 - val_loss: 0.4464 - val_accuracy: 0.8040 - 19s/epoch - 297ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "63/63 - 19s - loss: 0.3811 - accuracy: 0.8357 - val_loss: 0.4146 - val_accuracy: 0.8160 - 19s/epoch - 295ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 19s - loss: 0.3500 - accuracy: 0.8499 - val_loss: 0.4117 - val_accuracy: 0.8280 - 19s/epoch - 303ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 19s - loss: 0.3184 - accuracy: 0.8659 - val_loss: 0.4147 - val_accuracy: 0.8140 - 19s/epoch - 303ms/step\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 1s 35ms/step\n",
      "63/63 - 18s - loss: 0.2868 - accuracy: 0.8821 - val_loss: 0.3473 - val_accuracy: 0.8560 - 18s/epoch - 288ms/step\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 1s 37ms/step\n",
      "63/63 - 18s - loss: 0.2644 - accuracy: 0.8951 - val_loss: 0.3363 - val_accuracy: 0.8780 - 18s/epoch - 287ms/step\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 1s 36ms/step\n",
      "63/63 - 20s - loss: 0.2614 - accuracy: 0.8941 - val_loss: 0.4456 - val_accuracy: 0.8340 - 20s/epoch - 311ms/step\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 19s - loss: 0.2419 - accuracy: 0.9041 - val_loss: 0.3420 - val_accuracy: 0.8700 - 19s/epoch - 300ms/step\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.3363 - accuracy: 0.8780\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-9\n",
      "{'filter_size': 7, 'filter_num': 32}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "63/63 - 20s - loss: 0.6816 - accuracy: 0.6618 - val_loss: 0.5078 - val_accuracy: 0.7200 - 20s/epoch - 323ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "63/63 - 18s - loss: 0.4424 - accuracy: 0.7927 - val_loss: 0.4463 - val_accuracy: 0.8240 - 18s/epoch - 290ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 19s - loss: 0.3878 - accuracy: 0.8307 - val_loss: 0.3921 - val_accuracy: 0.8300 - 19s/epoch - 301ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 49ms/step\n",
      "63/63 - 20s - loss: 0.3355 - accuracy: 0.8614 - val_loss: 0.4044 - val_accuracy: 0.8100 - 20s/epoch - 316ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 20s - loss: 0.3105 - accuracy: 0.8704 - val_loss: 0.3759 - val_accuracy: 0.8220 - 20s/epoch - 325ms/step\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 19s - loss: 0.2973 - accuracy: 0.8776 - val_loss: 0.3758 - val_accuracy: 0.8620 - 19s/epoch - 308ms/step\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "63/63 - 19s - loss: 0.2755 - accuracy: 0.8889 - val_loss: 0.3539 - val_accuracy: 0.8500 - 19s/epoch - 302ms/step\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 19s - loss: 0.2595 - accuracy: 0.8976 - val_loss: 0.3315 - val_accuracy: 0.8760 - 19s/epoch - 304ms/step\n",
      "Epoch 9/15\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "63/63 - 20s - loss: 0.2298 - accuracy: 0.9096 - val_loss: 0.3519 - val_accuracy: 0.8680 - 20s/epoch - 323ms/step\n",
      "Epoch 10/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 20s - loss: 0.2291 - accuracy: 0.9103 - val_loss: 0.4149 - val_accuracy: 0.8160 - 20s/epoch - 314ms/step\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.3315 - accuracy: 0.8760\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-10\n",
      "{'filter_size': 7, 'filter_num': 64}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 46ms/step\n",
      "63/63 - 24s - loss: 0.8210 - accuracy: 0.6688 - val_loss: 0.5055 - val_accuracy: 0.7400 - 24s/epoch - 375ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 22s - loss: 0.4329 - accuracy: 0.8052 - val_loss: 0.4612 - val_accuracy: 0.7620 - 22s/epoch - 349ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 19s - loss: 0.3614 - accuracy: 0.8514 - val_loss: 0.3743 - val_accuracy: 0.8400 - 19s/epoch - 309ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "63/63 - 20s - loss: 0.3315 - accuracy: 0.8609 - val_loss: 0.3925 - val_accuracy: 0.8100 - 20s/epoch - 317ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 21s - loss: 0.3087 - accuracy: 0.8736 - val_loss: 0.3890 - val_accuracy: 0.8300 - 21s/epoch - 330ms/step\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.3743 - accuracy: 0.8400\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-11\n",
      "{'filter_size': 7, 'filter_num': 96}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 24s - loss: 0.6977 - accuracy: 0.6643 - val_loss: 0.5019 - val_accuracy: 0.7300 - 24s/epoch - 386ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "63/63 - 21s - loss: 0.4183 - accuracy: 0.8174 - val_loss: 0.4338 - val_accuracy: 0.8280 - 21s/epoch - 329ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 45ms/step\n",
      "63/63 - 20s - loss: 0.3590 - accuracy: 0.8514 - val_loss: 0.4458 - val_accuracy: 0.7720 - 20s/epoch - 321ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 57ms/step\n",
      "63/63 - 21s - loss: 0.3148 - accuracy: 0.8611 - val_loss: 0.3641 - val_accuracy: 0.8420 - 21s/epoch - 341ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 36ms/step\n",
      "63/63 - 21s - loss: 0.2833 - accuracy: 0.8839 - val_loss: 0.3471 - val_accuracy: 0.8440 - 21s/epoch - 333ms/step\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 1s 48ms/step\n",
      "63/63 - 23s - loss: 0.2637 - accuracy: 0.8916 - val_loss: 0.3031 - val_accuracy: 0.8940 - 23s/epoch - 371ms/step\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 1s 50ms/step\n",
      "63/63 - 24s - loss: 0.2363 - accuracy: 0.9081 - val_loss: 0.3130 - val_accuracy: 0.8740 - 24s/epoch - 388ms/step\n",
      "Epoch 8/15\n",
      "16/16 [==============================] - 1s 43ms/step\n",
      "63/63 - 22s - loss: 0.2225 - accuracy: 0.9126 - val_loss: 0.3109 - val_accuracy: 0.8780 - 22s/epoch - 350ms/step\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.3031 - accuracy: 0.8940\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-12\n",
      "{'filter_size': 7, 'filter_num': 128}\n",
      "Epoch 1/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 23s - loss: 0.6883 - accuracy: 0.6201 - val_loss: 0.5317 - val_accuracy: 0.7280 - 23s/epoch - 367ms/step\n",
      "Epoch 2/15\n",
      "16/16 [==============================] - 1s 41ms/step\n",
      "63/63 - 20s - loss: 0.4501 - accuracy: 0.7975 - val_loss: 0.4680 - val_accuracy: 0.7680 - 20s/epoch - 321ms/step\n",
      "Epoch 3/15\n",
      "16/16 [==============================] - 1s 38ms/step\n",
      "63/63 - 19s - loss: 0.3861 - accuracy: 0.8322 - val_loss: 0.4514 - val_accuracy: 0.7740 - 19s/epoch - 306ms/step\n",
      "Epoch 4/15\n",
      "16/16 [==============================] - 1s 39ms/step\n",
      "63/63 - 19s - loss: 0.3346 - accuracy: 0.8569 - val_loss: 0.3570 - val_accuracy: 0.8640 - 19s/epoch - 308ms/step\n",
      "Epoch 5/15\n",
      "16/16 [==============================] - 1s 42ms/step\n",
      "63/63 - 19s - loss: 0.3244 - accuracy: 0.8689 - val_loss: 0.3444 - val_accuracy: 0.8540 - 19s/epoch - 301ms/step\n",
      "Epoch 6/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 20s - loss: 0.2918 - accuracy: 0.8781 - val_loss: 0.3708 - val_accuracy: 0.8340 - 20s/epoch - 312ms/step\n",
      "Epoch 7/15\n",
      "16/16 [==============================] - 1s 40ms/step\n",
      "63/63 - 20s - loss: 0.2699 - accuracy: 0.8874 - val_loss: 0.3530 - val_accuracy: 0.8600 - 20s/epoch - 315ms/step\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.3444 - accuracy: 0.8540\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelG 2/fit/run-12\\assets\n"
     ]
    }
   ],
   "source": [
    "#Log the hyperparameter to the TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "def run(log_dir, hparams,session_num):\n",
    "    hyperparameter_writer = tf.summary.create_file_writer(log_dir)\n",
    "    \n",
    "    \n",
    "    with hyperparameter_writer.as_default():\n",
    "        hp.hparams(hparams) #record the values used in this trial\n",
    "        accuracy = train_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#Train the model with the different hyperparameters\n",
    "session_num = 1\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "        hparams ={\n",
    "        HP_FILTER_SIZE: filter_size,\n",
    "        HP_FILTER_NUM : filter_num\n",
    "        }\n",
    "        \n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('---Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('Logs/ModelG 2/hparam_tuning/' + run_name, hparams, session_num)\n",
    "        \n",
    "        session_num += 1\n",
    "       \n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a19ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a38f19ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bec5f88efa2b9a10\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bec5f88efa2b9a10\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'Logs/ModelG 2/hparam_tuning'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e1505de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2de4c2c132e653bb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2de4c2c132e653bb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'Logs/ModelG 2/fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29b717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09562aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
