{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a2730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rerun the female model; you didn't output the correct number of labels. You did \"4\" instead of \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b10c8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import io\n",
    "import itertools\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, LambdaCallback\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "# import datetime\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c0194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset encoding explaination.\n",
    "#image labelling - 0=glasses/sunglasses. 1= trousers/jeans. 3= shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba424d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the datasets and preprocess\n",
    "\n",
    "data_train = np.load(r'Full Dataset/Trousers & Jeans - Female - Test.npz')\n",
    "data_validation = np.load(r'Full Dataset/Trousers & Jeans - Female - Validation.npz')\n",
    "data_test = np.load(r'Full Dataset/Trousers & Jeans - Female - Test.npz')\n",
    "\n",
    "\n",
    "#t extract the arrays from dataset into input(images) and target(labels)\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_validation['images']\n",
    "labels_val = data_validation['labels']\n",
    "\n",
    "\n",
    "images_test = data_test['images']\n",
    "labels_test = data_test['labels']\n",
    "\n",
    "#Pixel-wise normalization of the training, validation and testing data\n",
    "images_train = images_train/255.0\n",
    "images_val  = images_val/255.0\n",
    "images_test = images_test/255.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ab0b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameters\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 15\n",
    "\n",
    "#Define the hyperparamets to tune and the variations we want to test.\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([3,5,7]))\n",
    "HP_FILTER_NUM = hp.HParam('filter_num', hp.Discrete([32, 64, 96, 128]))\n",
    "\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "#Log the hyperparameter with the file writer\n",
    "with tf.summary.create_file_writer('Logs/ModelF 1/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE, HP_FILTER_NUM], \n",
    "        metrics= [hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de25b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hparams,session_num):\n",
    "    \n",
    "    \n",
    "#Create and train the model\n",
    "\n",
    "\n",
    "    \n",
    "    model = Sequential([\n",
    "                Conv2D(32, 3, activation= 'relu', input_shape=(120,90,3)),\n",
    "                MaxPooling2D(pool_size=(2,2)),\n",
    "                Conv2D(64, 3, activation= 'relu'),\n",
    "                MaxPooling2D(pool_size=(2,2)),\n",
    "                Flatten(),\n",
    "                Dense(64, activation = 'relu'),\n",
    "                \n",
    "                Dense(2)\n",
    "    ])\n",
    "\n",
    "\n",
    "#describe the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "#Compile the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "    log_dir = f\"Logs/ModelF 1/fit/run-{session_num}\"\n",
    "\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "#Plot_to_image\n",
    "\n",
    "    def plot_confusion_matrix(cm, class_names):\n",
    " \n",
    "        figure = plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.colorbar()\n",
    "        tick_marks = np.arange(len(class_names))\n",
    "        plt.xticks(tick_marks, class_names, rotation=45)\n",
    "        plt.yticks(tick_marks, class_names)\n",
    "\n",
    "        # Compute the labels from the normalized confusion matrix.\n",
    "        labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "        # Use white text if squares are dark; otherwise black.\n",
    "        threshold = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        return figure\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def plot_to_image(figure):\n",
    "       \n",
    "        # Save the plot to a PNG in memory.\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        # Closing the figure prevents it from being displayed directly inside\n",
    "        # the notebook.\n",
    "        plt.close(figure)\n",
    "        buf.seek(0)\n",
    "        # Convert PNG buffer to TF image\n",
    "        image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "        # Add the batch dimension\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        return image\n",
    "\n",
    "\n",
    "        \n",
    "    # log the confusion matrix as a heatmap\n",
    "    file_writer_cm = tf.summary.create_file_writer(log_dir + '/cm')\n",
    "\n",
    "\n",
    "    def log_confusion_matrix(epoch, logs):\n",
    "        # Use the model to predict the values from the validation dataset.\n",
    "        val_pred_raw = model.predict(images_val)\n",
    "        val_pred = np.argmax(val_pred_raw, axis=1)\n",
    "\n",
    "        # Calculate the confusion matrix.\n",
    "        cm = confusion_matrix(labels_val, val_pred)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        figure = plot_confusion_matrix(cm, class_names=[\"Trouser\", \"Jeans\"])\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with file_writer_cm.as_default():\n",
    "            tf.summary.image(\"Confusion_matrix\", cm_image, step=epoch)\n",
    "\n",
    "    # Define the per-epoch callback.\n",
    "    cm_callback = LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "\n",
    "\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor= 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "\n",
    "\n",
    "#Train the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val, labels_val),\n",
    "        verbose =2\n",
    "    )\n",
    "\n",
    "    _,accuracy = model.evaluate(images_val, labels_val)\n",
    "\n",
    "    model.save(f\"saved_model/ModelF 1/fit/run-{session_num}\")\n",
    "\n",
    "\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fb505ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-1\n",
      "{'filter_size': 3, 'filter_num': 32}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 6s - loss: 1.5158 - accuracy: 0.4720 - val_loss: 1.0599 - val_accuracy: 0.5160 - 6s/epoch - 2s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.8703 - accuracy: 0.5080 - val_loss: 0.6965 - val_accuracy: 0.5160 - 4s/epoch - 956ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.6840 - accuracy: 0.5120 - val_loss: 0.6719 - val_accuracy: 0.6760 - 4s/epoch - 888ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.6627 - accuracy: 0.7280 - val_loss: 0.6385 - val_accuracy: 0.6920 - 4s/epoch - 879ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.6092 - accuracy: 0.7520 - val_loss: 0.6130 - val_accuracy: 0.6760 - 3s/epoch - 850ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 3s - loss: 0.5858 - accuracy: 0.7160 - val_loss: 0.6759 - val_accuracy: 0.6200 - 3s/epoch - 831ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 3s - loss: 0.5558 - accuracy: 0.7440 - val_loss: 0.5988 - val_accuracy: 0.7120 - 3s/epoch - 860ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.5048 - accuracy: 0.7680 - val_loss: 0.5990 - val_accuracy: 0.6960 - 3s/epoch - 845ms/step\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 4s - loss: 0.4835 - accuracy: 0.7800 - val_loss: 0.5935 - val_accuracy: 0.7280 - 4s/epoch - 919ms/step\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.4529 - accuracy: 0.7880 - val_loss: 0.5777 - val_accuracy: 0.7000 - 3s/epoch - 845ms/step\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.4462 - accuracy: 0.7880 - val_loss: 0.5503 - val_accuracy: 0.7600 - 3s/epoch - 843ms/step\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.4038 - accuracy: 0.8280 - val_loss: 0.5322 - val_accuracy: 0.7680 - 3s/epoch - 850ms/step\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.3715 - accuracy: 0.8280 - val_loss: 0.5568 - val_accuracy: 0.7320 - 3s/epoch - 853ms/step\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.3599 - accuracy: 0.8320 - val_loss: 0.5468 - val_accuracy: 0.7520 - 3s/epoch - 857ms/step\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.5322 - accuracy: 0.7680\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-2\n",
      "{'filter_size': 3, 'filter_num': 64}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 6s - loss: 1.2144 - accuracy: 0.5240 - val_loss: 0.6625 - val_accuracy: 0.5080 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 4s - loss: 0.7140 - accuracy: 0.4760 - val_loss: 0.6458 - val_accuracy: 0.6280 - 4s/epoch - 903ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 4s - loss: 0.6451 - accuracy: 0.7000 - val_loss: 0.6292 - val_accuracy: 0.6960 - 4s/epoch - 927ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 4s - loss: 0.6067 - accuracy: 0.7480 - val_loss: 0.6288 - val_accuracy: 0.6600 - 4s/epoch - 919ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.5672 - accuracy: 0.6880 - val_loss: 0.5840 - val_accuracy: 0.7360 - 4s/epoch - 898ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.4986 - accuracy: 0.8040 - val_loss: 0.5874 - val_accuracy: 0.7520 - 3s/epoch - 849ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.4830 - accuracy: 0.7800 - val_loss: 0.5757 - val_accuracy: 0.7600 - 3s/epoch - 841ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 3s - loss: 0.4269 - accuracy: 0.8160 - val_loss: 0.5414 - val_accuracy: 0.7480 - 3s/epoch - 844ms/step\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.3981 - accuracy: 0.8240 - val_loss: 0.5552 - val_accuracy: 0.7360 - 3s/epoch - 842ms/step\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 4s - loss: 0.3609 - accuracy: 0.8280 - val_loss: 0.5260 - val_accuracy: 0.7680 - 4s/epoch - 882ms/step\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.3468 - accuracy: 0.8440 - val_loss: 0.5808 - val_accuracy: 0.7160 - 3s/epoch - 849ms/step\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.3199 - accuracy: 0.8440 - val_loss: 0.5470 - val_accuracy: 0.7440 - 3s/epoch - 861ms/step\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 0.5260 - accuracy: 0.7680\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-3\n",
      "{'filter_size': 3, 'filter_num': 96}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 6s - loss: 1.6383 - accuracy: 0.5240 - val_loss: 0.8787 - val_accuracy: 0.5160 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 4s - loss: 0.7511 - accuracy: 0.5720 - val_loss: 0.6753 - val_accuracy: 0.5600 - 4s/epoch - 928ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 71ms/step\n",
      "4/4 - 4s - loss: 0.6198 - accuracy: 0.6040 - val_loss: 0.6371 - val_accuracy: 0.6000 - 4s/epoch - 909ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 4s - loss: 0.5838 - accuracy: 0.7160 - val_loss: 0.6003 - val_accuracy: 0.6800 - 4s/epoch - 906ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.5285 - accuracy: 0.7480 - val_loss: 0.5692 - val_accuracy: 0.7120 - 4s/epoch - 885ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 3s - loss: 0.4815 - accuracy: 0.7840 - val_loss: 0.5515 - val_accuracy: 0.7480 - 3s/epoch - 844ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 3s - loss: 0.4516 - accuracy: 0.7880 - val_loss: 0.5465 - val_accuracy: 0.7200 - 3s/epoch - 853ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.4469 - accuracy: 0.7840 - val_loss: 0.5378 - val_accuracy: 0.7600 - 3s/epoch - 844ms/step\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 3s - loss: 0.4087 - accuracy: 0.8120 - val_loss: 0.5539 - val_accuracy: 0.7240 - 3s/epoch - 842ms/step\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.3887 - accuracy: 0.8120 - val_loss: 0.5553 - val_accuracy: 0.7560 - 3s/epoch - 857ms/step\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.5378 - accuracy: 0.7600\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-4\n",
      "{'filter_size': 3, 'filter_num': 128}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 6s - loss: 2.1000 - accuracy: 0.5720 - val_loss: 1.4742 - val_accuracy: 0.4840 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 4s - loss: 1.0896 - accuracy: 0.4920 - val_loss: 0.7237 - val_accuracy: 0.4840 - 4s/epoch - 937ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 4s - loss: 0.6952 - accuracy: 0.4920 - val_loss: 0.6930 - val_accuracy: 0.5160 - 4s/epoch - 920ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 67ms/step\n",
      "4/4 - 4s - loss: 0.6932 - accuracy: 0.5080 - val_loss: 0.6926 - val_accuracy: 0.5160 - 4s/epoch - 935ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.6926 - accuracy: 0.5080 - val_loss: 0.6920 - val_accuracy: 0.5160 - 3s/epoch - 851ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.6917 - accuracy: 0.5080 - val_loss: 0.6911 - val_accuracy: 0.5160 - 3s/epoch - 839ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.6902 - accuracy: 0.5080 - val_loss: 0.6890 - val_accuracy: 0.5160 - 3s/epoch - 846ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 3s - loss: 0.6874 - accuracy: 0.5080 - val_loss: 0.6857 - val_accuracy: 0.5160 - 3s/epoch - 849ms/step\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.6844 - accuracy: 0.5080 - val_loss: 0.6793 - val_accuracy: 0.5160 - 3s/epoch - 845ms/step\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.6768 - accuracy: 0.5080 - val_loss: 0.6721 - val_accuracy: 0.5160 - 3s/epoch - 845ms/step\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 3s - loss: 0.6674 - accuracy: 0.5080 - val_loss: 0.6575 - val_accuracy: 0.5160 - 3s/epoch - 853ms/step\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.6509 - accuracy: 0.5080 - val_loss: 0.6506 - val_accuracy: 0.5160 - 3s/epoch - 844ms/step\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.6390 - accuracy: 0.5080 - val_loss: 0.6439 - val_accuracy: 0.5160 - 3s/epoch - 846ms/step\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.6297 - accuracy: 0.5080 - val_loss: 0.6425 - val_accuracy: 0.5160 - 3s/epoch - 847ms/step\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 3s - loss: 0.6248 - accuracy: 0.5080 - val_loss: 0.6406 - val_accuracy: 0.5160 - 3s/epoch - 858ms/step\n",
      "8/8 [==============================] - 1s 61ms/step - loss: 0.6406 - accuracy: 0.5160\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-5\n",
      "{'filter_size': 5, 'filter_num': 32}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 6s - loss: 1.4433 - accuracy: 0.5240 - val_loss: 0.6605 - val_accuracy: 0.6120 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.7041 - accuracy: 0.5240 - val_loss: 0.6720 - val_accuracy: 0.5600 - 4s/epoch - 930ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 3s - loss: 0.6138 - accuracy: 0.7120 - val_loss: 0.6163 - val_accuracy: 0.7120 - 3s/epoch - 855ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 4s - loss: 0.5596 - accuracy: 0.7320 - val_loss: 0.5935 - val_accuracy: 0.7120 - 4s/epoch - 918ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 65ms/step\n",
      "4/4 - 4s - loss: 0.4723 - accuracy: 0.7760 - val_loss: 0.6092 - val_accuracy: 0.7400 - 4s/epoch - 892ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 4s - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.5886 - val_accuracy: 0.7400 - 4s/epoch - 887ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.4149 - accuracy: 0.8080 - val_loss: 0.5813 - val_accuracy: 0.7240 - 3s/epoch - 859ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.4072 - accuracy: 0.8040 - val_loss: 0.5485 - val_accuracy: 0.7320 - 3s/epoch - 843ms/step\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.3685 - accuracy: 0.8240 - val_loss: 0.5962 - val_accuracy: 0.7280 - 3s/epoch - 849ms/step\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.3658 - accuracy: 0.8360 - val_loss: 0.5569 - val_accuracy: 0.7520 - 3s/epoch - 845ms/step\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.5485 - accuracy: 0.7320\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-6\n",
      "{'filter_size': 5, 'filter_num': 64}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 6s - loss: 1.0164 - accuracy: 0.5000 - val_loss: 0.6613 - val_accuracy: 0.5280 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 66ms/step\n",
      "4/4 - 4s - loss: 0.6585 - accuracy: 0.5640 - val_loss: 0.6316 - val_accuracy: 0.6640 - 4s/epoch - 933ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 65ms/step\n",
      "4/4 - 4s - loss: 0.6065 - accuracy: 0.6720 - val_loss: 0.6139 - val_accuracy: 0.6760 - 4s/epoch - 964ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 4s - loss: 0.5526 - accuracy: 0.7360 - val_loss: 0.5761 - val_accuracy: 0.7440 - 4s/epoch - 908ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 65ms/step\n",
      "4/4 - 4s - loss: 0.4999 - accuracy: 0.7720 - val_loss: 0.5707 - val_accuracy: 0.7440 - 4s/epoch - 932ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 4s - loss: 0.4524 - accuracy: 0.7840 - val_loss: 0.5829 - val_accuracy: 0.7160 - 4s/epoch - 919ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 66ms/step\n",
      "4/4 - 4s - loss: 0.4208 - accuracy: 0.8120 - val_loss: 0.5568 - val_accuracy: 0.7520 - 4s/epoch - 923ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 4s - loss: 0.3899 - accuracy: 0.8280 - val_loss: 0.5550 - val_accuracy: 0.7600 - 4s/epoch - 916ms/step\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.3776 - accuracy: 0.8240 - val_loss: 0.5542 - val_accuracy: 0.7560 - 4s/epoch - 883ms/step\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 3s - loss: 0.3465 - accuracy: 0.8480 - val_loss: 0.6073 - val_accuracy: 0.7320 - 3s/epoch - 860ms/step\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 3s - loss: 0.3516 - accuracy: 0.8280 - val_loss: 0.5778 - val_accuracy: 0.7440 - 3s/epoch - 826ms/step\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.5542 - accuracy: 0.7560\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-6\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-6\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-7\n",
      "{'filter_size': 5, 'filter_num': 96}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 6s - loss: 1.5449 - accuracy: 0.5160 - val_loss: 0.6721 - val_accuracy: 0.5120 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.7514 - accuracy: 0.5120 - val_loss: 0.6661 - val_accuracy: 0.5880 - 3s/epoch - 848ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 3s - loss: 0.6450 - accuracy: 0.5720 - val_loss: 0.6423 - val_accuracy: 0.5440 - 3s/epoch - 850ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 4s - loss: 0.6135 - accuracy: 0.6680 - val_loss: 0.6019 - val_accuracy: 0.7080 - 4s/epoch - 1s/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 69ms/step\n",
      "4/4 - 4s - loss: 0.5435 - accuracy: 0.7720 - val_loss: 0.5608 - val_accuracy: 0.7120 - 4s/epoch - 887ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 3s - loss: 0.4769 - accuracy: 0.8000 - val_loss: 0.6131 - val_accuracy: 0.7000 - 3s/epoch - 846ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 3s - loss: 0.4937 - accuracy: 0.7360 - val_loss: 0.6293 - val_accuracy: 0.6920 - 3s/epoch - 861ms/step\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.5608 - accuracy: 0.7120\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-7\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-7\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-8\n",
      "{'filter_size': 5, 'filter_num': 128}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 6s - loss: 2.0093 - accuracy: 0.5200 - val_loss: 0.8894 - val_accuracy: 0.5160 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.7272 - accuracy: 0.5160 - val_loss: 0.7070 - val_accuracy: 0.4920 - 4s/epoch - 928ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 4s - loss: 0.6775 - accuracy: 0.5880 - val_loss: 0.6792 - val_accuracy: 0.6320 - 4s/epoch - 914ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.6688 - accuracy: 0.6440 - val_loss: 0.6526 - val_accuracy: 0.6560 - 4s/epoch - 891ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 72ms/step\n",
      "4/4 - 4s - loss: 0.6174 - accuracy: 0.6720 - val_loss: 0.8092 - val_accuracy: 0.5120 - 4s/epoch - 964ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 58ms/step\n",
      "4/4 - 4s - loss: 0.6102 - accuracy: 0.6600 - val_loss: 0.5919 - val_accuracy: 0.6800 - 4s/epoch - 880ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.5333 - accuracy: 0.7280 - val_loss: 0.5837 - val_accuracy: 0.7200 - 3s/epoch - 820ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 58ms/step\n",
      "4/4 - 3s - loss: 0.4744 - accuracy: 0.7680 - val_loss: 0.5711 - val_accuracy: 0.7280 - 3s/epoch - 835ms/step\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 3s - loss: 0.4387 - accuracy: 0.7880 - val_loss: 0.5564 - val_accuracy: 0.7480 - 3s/epoch - 812ms/step\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.4180 - accuracy: 0.8080 - val_loss: 0.5445 - val_accuracy: 0.7320 - 3s/epoch - 839ms/step\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.4052 - accuracy: 0.7920 - val_loss: 0.5829 - val_accuracy: 0.7160 - 3s/epoch - 858ms/step\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 3s - loss: 0.4030 - accuracy: 0.8000 - val_loss: 0.5581 - val_accuracy: 0.7400 - 3s/epoch - 850ms/step\n",
      "8/8 [==============================] - 1s 61ms/step - loss: 0.5445 - accuracy: 0.7320\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-8\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-8\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-9\n",
      "{'filter_size': 7, 'filter_num': 32}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 6s - loss: 2.6471 - accuracy: 0.5400 - val_loss: 1.1085 - val_accuracy: 0.4840 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 3s - loss: 0.8904 - accuracy: 0.4920 - val_loss: 0.6963 - val_accuracy: 0.4840 - 3s/epoch - 873ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 65ms/step\n",
      "4/4 - 4s - loss: 0.7023 - accuracy: 0.4680 - val_loss: 0.6833 - val_accuracy: 0.5200 - 4s/epoch - 902ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 67ms/step\n",
      "4/4 - 4s - loss: 0.6663 - accuracy: 0.6240 - val_loss: 0.6973 - val_accuracy: 0.5240 - 4s/epoch - 909ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 3s - loss: 0.6536 - accuracy: 0.6160 - val_loss: 0.6397 - val_accuracy: 0.7160 - 3s/epoch - 840ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 65ms/step\n",
      "4/4 - 4s - loss: 0.5499 - accuracy: 0.7680 - val_loss: 0.6362 - val_accuracy: 0.7080 - 4s/epoch - 878ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 4s - loss: 0.4973 - accuracy: 0.8000 - val_loss: 0.6897 - val_accuracy: 0.6760 - 4s/epoch - 916ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 3s - loss: 0.4722 - accuracy: 0.7800 - val_loss: 0.6867 - val_accuracy: 0.6800 - 3s/epoch - 850ms/step\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 0.6362 - accuracy: 0.7080\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-9\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-10\n",
      "{'filter_size': 7, 'filter_num': 64}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 6s - loss: 1.8004 - accuracy: 0.4440 - val_loss: 0.7040 - val_accuracy: 0.5160 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 4s - loss: 0.6791 - accuracy: 0.6520 - val_loss: 0.6516 - val_accuracy: 0.6840 - 4s/epoch - 887ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 4s - loss: 0.6306 - accuracy: 0.7160 - val_loss: 0.6195 - val_accuracy: 0.6840 - 4s/epoch - 891ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 4s - loss: 0.5887 - accuracy: 0.7400 - val_loss: 0.6326 - val_accuracy: 0.6440 - 4s/epoch - 883ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 4s - loss: 0.5578 - accuracy: 0.7040 - val_loss: 0.6451 - val_accuracy: 0.6680 - 4s/epoch - 907ms/step\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.6195 - accuracy: 0.6840\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-10\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-10\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-11\n",
      "{'filter_size': 7, 'filter_num': 96}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 6s - loss: 1.7431 - accuracy: 0.4760 - val_loss: 0.7503 - val_accuracy: 0.4840 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 4s - loss: 0.7064 - accuracy: 0.5000 - val_loss: 0.6804 - val_accuracy: 0.5120 - 4s/epoch - 903ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 67ms/step\n",
      "4/4 - 4s - loss: 0.6571 - accuracy: 0.6000 - val_loss: 0.6737 - val_accuracy: 0.5840 - 4s/epoch - 922ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 66ms/step\n",
      "4/4 - 3s - loss: 0.6405 - accuracy: 0.6360 - val_loss: 0.6301 - val_accuracy: 0.6720 - 3s/epoch - 867ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.5973 - accuracy: 0.7400 - val_loss: 0.6051 - val_accuracy: 0.7240 - 4s/epoch - 875ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 0s 55ms/step\n",
      "4/4 - 3s - loss: 0.5491 - accuracy: 0.7480 - val_loss: 0.5966 - val_accuracy: 0.6720 - 3s/epoch - 810ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 0s 58ms/step\n",
      "4/4 - 3s - loss: 0.5022 - accuracy: 0.7760 - val_loss: 0.5850 - val_accuracy: 0.7360 - 3s/epoch - 797ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.4823 - accuracy: 0.7640 - val_loss: 0.5762 - val_accuracy: 0.7240 - 3s/epoch - 822ms/step\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 3s - loss: 0.4641 - accuracy: 0.7840 - val_loss: 0.5935 - val_accuracy: 0.6960 - 3s/epoch - 816ms/step\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 0s 58ms/step\n",
      "4/4 - 3s - loss: 0.4450 - accuracy: 0.7800 - val_loss: 0.5893 - val_accuracy: 0.7360 - 3s/epoch - 824ms/step\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.5762 - accuracy: 0.7240\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-11\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-11\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-12\n",
      "{'filter_size': 7, 'filter_num': 128}\n",
      "Epoch 1/15\n",
      "8/8 [==============================] - 1s 68ms/step\n",
      "4/4 - 6s - loss: 1.6996 - accuracy: 0.5040 - val_loss: 0.9012 - val_accuracy: 0.5160 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 4s - loss: 0.8105 - accuracy: 0.5080 - val_loss: 0.7000 - val_accuracy: 0.5160 - 4s/epoch - 891ms/step\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.6910 - accuracy: 0.5240 - val_loss: 0.6798 - val_accuracy: 0.5160 - 4s/epoch - 888ms/step\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 4s - loss: 0.6770 - accuracy: 0.5080 - val_loss: 0.6714 - val_accuracy: 0.5160 - 4s/epoch - 878ms/step\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 1s 61ms/step\n",
      "4/4 - 4s - loss: 0.7019 - accuracy: 0.5840 - val_loss: 0.6704 - val_accuracy: 0.5320 - 4s/epoch - 886ms/step\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 1s 66ms/step\n",
      "4/4 - 4s - loss: 0.6722 - accuracy: 0.5920 - val_loss: 0.6529 - val_accuracy: 0.6640 - 4s/epoch - 906ms/step\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 1s 60ms/step\n",
      "4/4 - 3s - loss: 0.6423 - accuracy: 0.6360 - val_loss: 0.6410 - val_accuracy: 0.6160 - 3s/epoch - 846ms/step\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 1s 57ms/step\n",
      "4/4 - 3s - loss: 0.6308 - accuracy: 0.6600 - val_loss: 0.6189 - val_accuracy: 0.6760 - 3s/epoch - 835ms/step\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 1s 58ms/step\n",
      "4/4 - 3s - loss: 0.5882 - accuracy: 0.7360 - val_loss: 0.6054 - val_accuracy: 0.7200 - 3s/epoch - 831ms/step\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 1s 64ms/step\n",
      "4/4 - 3s - loss: 0.5543 - accuracy: 0.7800 - val_loss: 0.5730 - val_accuracy: 0.6880 - 3s/epoch - 845ms/step\n",
      "Epoch 11/15\n",
      "8/8 [==============================] - 1s 65ms/step\n",
      "4/4 - 3s - loss: 0.5280 - accuracy: 0.7640 - val_loss: 0.5628 - val_accuracy: 0.6800 - 3s/epoch - 868ms/step\n",
      "Epoch 12/15\n",
      "8/8 [==============================] - 1s 59ms/step\n",
      "4/4 - 3s - loss: 0.4759 - accuracy: 0.7920 - val_loss: 0.5733 - val_accuracy: 0.7440 - 3s/epoch - 810ms/step\n",
      "Epoch 13/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 3s - loss: 0.4636 - accuracy: 0.8040 - val_loss: 0.5535 - val_accuracy: 0.7360 - 3s/epoch - 866ms/step\n",
      "Epoch 14/15\n",
      "8/8 [==============================] - 1s 62ms/step\n",
      "4/4 - 4s - loss: 0.4384 - accuracy: 0.7960 - val_loss: 0.5495 - val_accuracy: 0.7000 - 4s/epoch - 897ms/step\n",
      "Epoch 15/15\n",
      "8/8 [==============================] - 1s 63ms/step\n",
      "4/4 - 4s - loss: 0.4202 - accuracy: 0.8040 - val_loss: 0.5332 - val_accuracy: 0.7600 - 4s/epoch - 911ms/step\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 0.5332 - accuracy: 0.7600\n",
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-12\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/ModelF 1/fit/run-12\\assets\n"
     ]
    }
   ],
   "source": [
    "#Log the hyperparameter to the TensorBoard\n",
    "\n",
    "\n",
    "\n",
    "def run(log_dir, hparams,session_num):\n",
    "    hyperparameter_writer = tf.summary.create_file_writer(log_dir)\n",
    "    \n",
    "    \n",
    "    with hyperparameter_writer.as_default():\n",
    "        hp.hparams(hparams) #record the values used in this trial\n",
    "        accuracy = train_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#Train the model with the different hyperparameters\n",
    "session_num = 1\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "        hparams ={\n",
    "        HP_FILTER_SIZE: filter_size,\n",
    "        HP_FILTER_NUM : filter_num\n",
    "        }\n",
    "        \n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('---Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('Logs/ModelF 1/hparam_tuning/' + run_name, hparams, session_num)\n",
    "        \n",
    "        session_num += 1\n",
    "       \n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a19ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a38f19ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-56fee3b70c5205c4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-56fee3b70c5205c4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'Logs/ModelF 1/hparam_tuning'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e1505de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fae8088f737b509d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fae8088f737b509d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'Logs/ModelF 1/fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29b717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09562aa7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
