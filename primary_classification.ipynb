{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b10c8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import io\n",
    "import itertools\n",
    "import sklearn.metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "# import datetime\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c0194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset encoding explaination.\n",
    "#image labelling - 0=glasses/sunglasses. 1= trousers/jeans. 3= shoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ba424d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the datasets and preprocess\n",
    "\n",
    "data_train = np.load(r'Full Dataset/primary categories - Train.npz')\n",
    "data_validation = np.load(r'Full Dataset/primary categories - Validation.npz')\n",
    "data_Test = np.load(r'Full Dataset/primary categories - Test.npz')\n",
    "\n",
    "\n",
    "#t extract the arrays from dataset into input(images) and target(labels)\n",
    "images_train = data_train['images']\n",
    "labels_train = data_train['labels']\n",
    "\n",
    "images_val = data_train['images']\n",
    "labels_val = data_train['labels']\n",
    "\n",
    "\n",
    "images_test = data_train['images']\n",
    "labels_test = data_train['labels']\n",
    "\n",
    "#Pixel-wise normalization of the training, validation and testing data\n",
    "images_train = images_train/255.0\n",
    "images_val  = images_val/255.0\n",
    "images_test = images_test/255.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ab0b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameters\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1\n",
    "\n",
    "#Define the hyperparamets to tune and the variations we want to test.\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([3,5,7]))\n",
    "HP_FILTER_NUM = hp.HParam('filter_num', hp.Discrete(['32','64','96', '128']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "#Log the hyperparameter with the file writer\n",
    "with tf.summary.create_file_writer('Logs/Model 1/hparam_tuning/').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_FILTER_SIZE, HP_FILTER_NUM], \n",
    "        metrics= [hp.Metric(METRIC_ACCURACY, display_name='Accuracy')]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "61fc1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE THE MODEL AND TRAIN IT\n",
    "\n",
    "#Stop the model from overfitting ie whenever the validation loss increases\n",
    "#the code tells the model to stop when the val_loss starts to increase in two subsequent epochs\n",
    "\n",
    "#directory to store the TensorBoard logs  \n",
    "session_num = 0\n",
    "log_dir = f\"Logs/Model 1/fit/run-{session_num}\"\n",
    "summary_writer = tf.summary.create_file_writer(log_dir +'/cm')\n",
    "\n",
    "def train_model(hparams,session_num):\n",
    "    \n",
    "    \n",
    "#Create and train the model\n",
    "\n",
    "\n",
    "    \n",
    "    model = Sequential([\n",
    "                Conv2D(32, 3, activation= 'relu', input_shape=(120,90,3)),\n",
    "                MaxPooling2D(pool_size=(2,2)),\n",
    "                Conv2D(32, 3, activation= 'relu'),\n",
    "                MaxPooling2D(pool_size=(2,2)),\n",
    "                Flatten(),\n",
    "                Dense(3)\n",
    "    ])\n",
    "\n",
    "\n",
    "#describe the loss function\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "#Compile the model\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create a Confusion Matrix\n",
    "\n",
    "    def make_predictions(images_val):\n",
    "        predictions = model.predict(images_val)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def confusion_matrix_callback(epoch,log=None):\n",
    "\n",
    "        val_predict_raw= make_predictions(images_val)\n",
    "        val_predict = np.argmax(val_predict_raw, axis =1)\n",
    "\n",
    "\n",
    "\n",
    "        cm = confusion_matrix(labels_val, val_predict)\n",
    "        \n",
    "        \n",
    "         \n",
    "# log the confusion matrix as a heatmap\n",
    "\n",
    "    def log_confusion_matrix_to_tensorboard(cm,class_labels):\n",
    "     \n",
    "\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        sns.set(font_scale=1.2)  # Adjust the font size\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", square=True,\n",
    "                    xticklabels=class_labels,\n",
    "                    yticklabels=class_labels)\n",
    "\n",
    "\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title('Confusion Matrix')\n",
    "         \n",
    "        \n",
    "        with summary_writer.as_default():\n",
    "\n",
    "            tf.summary.image('Confusion Matrix', [plt.gcf()], step=step)\n",
    "            log_confusion_matrix_to_tensorboard(cm, class_labels= [\"Glasses/SUnglassses\", \"Trousers/Jeans\", \"Shoes\"],\n",
    "            step=0) \n",
    "            \n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "    cm_callback = tf.keras.callbacks.LambdaCallback(on_train_end=confusion_matrix_callback)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor= 'val_loss',\n",
    "        mode = 'auto',\n",
    "        min_delta = 0,\n",
    "        patience = 2,\n",
    "        verbose = 0,\n",
    "        restore_best_weights = True\n",
    "    )\n",
    "\n",
    "\n",
    "#Train the model\n",
    "    model.fit(\n",
    "        images_train,\n",
    "        labels_train,\n",
    "        epochs = EPOCHS,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        callbacks = [tensorboard_callback, cm_callback, early_stopping],\n",
    "        validation_data = (images_val, labels_val),\n",
    "        verbose =2\n",
    "    )\n",
    "\n",
    "    _,accuracy = model.evaluate(images_val, labels_val)\n",
    "\n",
    "#     model.save(f\"Logs/Model 1/fit/run-{session_num}\")\n",
    "\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4fb505ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log the confusion matrix and the hyperparameter to the TensorBoard\n",
    "\n",
    "def run(log_dir,hparams,session_num):\n",
    "    \n",
    "    summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "    \n",
    "    with summary_writer.as_default():\n",
    "        hp.hparams(hparams) #record the values used in this trial\n",
    "        accuracy = train_model(hparams, session_num)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "       \n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c60a19ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Starting trial: run-1\n",
      "{'filter_size': 3, 'filter_num': '128'}\n",
      "203/203 - 132s - loss: 0.0750 - accuracy: 0.9747 - val_loss: 0.0099 - val_accuracy: 0.9990 - 132s/epoch - 649ms/step\n",
      "406/406 [==============================] - 21s 50ms/step\n",
      "406/406 [==============================] - 25s 61ms/step - loss: 0.0099 - accuracy: 0.9990\n",
      "---Starting trial: run-2\n",
      "{'filter_size': 3, 'filter_num': '32'}\n",
      "203/203 - 128s - loss: 0.1117 - accuracy: 0.9677 - val_loss: 0.0124 - val_accuracy: 0.9988 - 128s/epoch - 629ms/step\n",
      "406/406 [==============================] - 24s 60ms/step\n",
      "406/406 [==============================] - 27s 66ms/step - loss: 0.0124 - accuracy: 0.9988\n",
      "---Starting trial: run-3\n",
      "{'filter_size': 3, 'filter_num': '64'}\n",
      "203/203 - 134s - loss: 0.0926 - accuracy: 0.9746 - val_loss: 0.0107 - val_accuracy: 0.9987 - 134s/epoch - 659ms/step\n",
      "406/406 [==============================] - 18s 44ms/step\n",
      "406/406 [==============================] - 24s 60ms/step - loss: 0.0107 - accuracy: 0.9987\n",
      "---Starting trial: run-4\n",
      "{'filter_size': 3, 'filter_num': '96'}\n",
      "203/203 - 107s - loss: 0.0905 - accuracy: 0.9718 - val_loss: 0.0122 - val_accuracy: 0.9990 - 107s/epoch - 528ms/step\n",
      "406/406 [==============================] - 22s 55ms/step\n",
      "406/406 [==============================] - 23s 55ms/step - loss: 0.0122 - accuracy: 0.9990\n",
      "---Starting trial: run-5\n",
      "{'filter_size': 5, 'filter_num': '128'}\n",
      "203/203 - 93s - loss: 0.0850 - accuracy: 0.9738 - val_loss: 0.0211 - val_accuracy: 0.9985 - 93s/epoch - 459ms/step\n",
      "406/406 [==============================] - 23s 56ms/step\n",
      "406/406 [==============================] - 21s 51ms/step - loss: 0.0211 - accuracy: 0.9985\n",
      "---Starting trial: run-6\n",
      "{'filter_size': 5, 'filter_num': '32'}\n",
      "203/203 - 85s - loss: 0.0924 - accuracy: 0.9752 - val_loss: 0.0262 - val_accuracy: 0.9982 - 85s/epoch - 420ms/step\n",
      "406/406 [==============================] - 21s 52ms/step\n",
      "406/406 [==============================] - 26s 63ms/step - loss: 0.0262 - accuracy: 0.9982\n",
      "---Starting trial: run-7\n",
      "{'filter_size': 5, 'filter_num': '64'}\n",
      "203/203 - 85s - loss: 0.0917 - accuracy: 0.9721 - val_loss: 0.0133 - val_accuracy: 0.9986 - 85s/epoch - 419ms/step\n",
      "406/406 [==============================] - 21s 53ms/step\n",
      "406/406 [==============================] - 20s 50ms/step - loss: 0.0133 - accuracy: 0.9986\n",
      "---Starting trial: run-8\n",
      "{'filter_size': 5, 'filter_num': '96'}\n",
      "203/203 - 96s - loss: 0.0720 - accuracy: 0.9809 - val_loss: 0.0151 - val_accuracy: 0.9985 - 96s/epoch - 475ms/step\n",
      "406/406 [==============================] - 22s 53ms/step\n",
      "406/406 [==============================] - 22s 55ms/step - loss: 0.0151 - accuracy: 0.9985\n",
      "---Starting trial: run-9\n",
      "{'filter_size': 7, 'filter_num': '128'}\n",
      "203/203 - 100s - loss: 0.0840 - accuracy: 0.9745 - val_loss: 0.0137 - val_accuracy: 0.9981 - 100s/epoch - 492ms/step\n",
      "406/406 [==============================] - 22s 54ms/step\n",
      "406/406 [==============================] - 22s 54ms/step - loss: 0.0137 - accuracy: 0.9981\n",
      "---Starting trial: run-10\n",
      "{'filter_size': 7, 'filter_num': '32'}\n",
      "203/203 - 95s - loss: 0.0768 - accuracy: 0.9777 - val_loss: 0.0314 - val_accuracy: 0.9904 - 95s/epoch - 467ms/step\n",
      "406/406 [==============================] - 23s 55ms/step\n",
      "406/406 [==============================] - 22s 54ms/step - loss: 0.0314 - accuracy: 0.9904\n",
      "---Starting trial: run-11\n",
      "{'filter_size': 7, 'filter_num': '64'}\n",
      "203/203 - 97s - loss: 0.0766 - accuracy: 0.9741 - val_loss: 0.0154 - val_accuracy: 0.9979 - 97s/epoch - 479ms/step\n",
      "406/406 [==============================] - 23s 56ms/step\n",
      "406/406 [==============================] - 23s 56ms/step - loss: 0.0154 - accuracy: 0.9979\n",
      "---Starting trial: run-12\n",
      "{'filter_size': 7, 'filter_num': '96'}\n",
      "203/203 - 92s - loss: 0.0809 - accuracy: 0.9729 - val_loss: 0.0117 - val_accuracy: 0.9983 - 92s/epoch - 451ms/step\n",
      "406/406 [==============================] - 22s 55ms/step\n",
      "406/406 [==============================] - 21s 52ms/step - loss: 0.0117 - accuracy: 0.9983\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "#Train the model with the different hyperparameters\n",
    "session_num = 1\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for filter_num in HP_FILTER_NUM.domain.values:\n",
    "        hparams ={\n",
    "        HP_FILTER_SIZE: filter_size,\n",
    "        HP_FILTER_NUM : filter_num\n",
    "        }\n",
    "        \n",
    "        run_name = \"run-%d\" % session_num\n",
    "        print('---Starting trial: %s' % run_name)\n",
    "        print({h.name: hparams[h] for h in hparams})\n",
    "        run('Logs/Model 1/hparam_tuning/' + run_name, hparams, session_num)\n",
    "        \n",
    "        session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a38f19ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8096), started 0:42:41 ago. (Use '!kill 8096' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-430846e38d4eda9\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-430846e38d4eda9\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'Logs/Model 1/hparam_tuning'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e1505de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-54badd3d91d864fa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-54badd3d91d864fa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir 'Logs/Model 1/fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29b717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
